{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMKdQjwvtmyP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TN4OmaZazp75"
   },
   "outputs": [],
   "source": [
    "#### Referencce \n",
    "#### https://www.tensorflow.org/tutorials/text/nmt_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "fU80Ao-AGaob",
    "outputId": "c4ba4cdb-81d6-4aa1-dd41-6511e62f1d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "6LgqUxYrwGQ_",
    "outputId": "3755e794-21a0-49b2-f0bd-a00044fe2c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/26. Attention Models (italian to english )/ita-eng\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/26. Attention Models (italian to english )/ita-eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fohEnR6_spEg"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/My Drive/26. Attention Models (italian to english )/ita-eng/ita.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NPPhl1ssiuI"
   },
   "outputs": [],
   "source": [
    "data  = open(data_path,encoding='UTF-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "xh8MTELIYY3J",
    "outputId": "47ecb0fe-852d-4662-b348-5fcbb8008e5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340432it [00:00, 636546.35it/s]\n"
     ]
    }
   ],
   "source": [
    "file = open(data_path, 'r', encoding = \"utf8\")\n",
    "data = []\n",
    "\n",
    "for line in tqdm(file):\n",
    "    pos = line.find(\"CC-BY\")\n",
    "    line = line[:pos-1]\n",
    "    \n",
    "    # Split the data into english and Italian\n",
    "    eng, ita = line.split('\\t')\n",
    "    \n",
    "    # form tuples of the data\n",
    "    text = eng, ita\n",
    "    data.append(text)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_FM_IJSZC3e"
   },
   "outputs": [],
   "source": [
    "raw_data_en, raw_data_it = list(zip(*data))\n",
    "raw_data_en, raw_data_it = list(raw_data_en), list(raw_data_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "OSGwdzLSZUvl",
    "outputId": "c319329f-807a-443b-d40b-1553b793de0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Italian</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ciao!</td>\n",
       "      <td>Hi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Italian English\n",
       "0   Ciao!     Hi."
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = pd.DataFrame(columns=['Italian','English'])\n",
    "\n",
    "lang['Italian'] = raw_data_it\n",
    "lang['English'] = raw_data_en\n",
    "\n",
    "lang.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4IdO-64YIiT"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "  \n",
    "  w = '<start>'+' ' + w +' '+ '<end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "gYeaSIc0zh51",
    "outputId": "6fbe2252-cd52-4759-cf84-d03aaaa158e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Italian</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; ciao ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; hi . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; corri ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; corra ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; correte ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; chi ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; who ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340426</th>\n",
       "      <td>&lt;start&gt; se vuoi sembrare un madrelingua , devi...</td>\n",
       "      <td>&lt;start&gt; if you want to sound like a native spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340427</th>\n",
       "      <td>&lt;start&gt; se vuoi sembrare un madrelingua , devi...</td>\n",
       "      <td>&lt;start&gt; if you want to sound like a native spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340428</th>\n",
       "      <td>&lt;start&gt; se vuoi sembrare un madrelingua , devi...</td>\n",
       "      <td>&lt;start&gt; if you want to sound like a native spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340429</th>\n",
       "      <td>&lt;start&gt; se qualcuno che non conosce il tuo bac...</td>\n",
       "      <td>&lt;start&gt; if someone who doesn't know your backg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340430</th>\n",
       "      <td>&lt;start&gt; senza dubbio esiste in questo mondo pr...</td>\n",
       "      <td>&lt;start&gt; doubtless there exists in this world p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340431 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Italian                                            English\n",
       "0                                    <start> ciao ! <end>                                 <start> hi . <end>\n",
       "1                                   <start> corri ! <end>                                <start> run ! <end>\n",
       "2                                   <start> corra ! <end>                                <start> run ! <end>\n",
       "3                                 <start> correte ! <end>                                <start> run ! <end>\n",
       "4                                     <start> chi ? <end>                                <start> who ? <end>\n",
       "...                                                   ...                                                ...\n",
       "340426  <start> se vuoi sembrare un madrelingua , devi...  <start> if you want to sound like a native spe...\n",
       "340427  <start> se vuoi sembrare un madrelingua , devi...  <start> if you want to sound like a native spe...\n",
       "340428  <start> se vuoi sembrare un madrelingua , devi...  <start> if you want to sound like a native spe...\n",
       "340429  <start> se qualcuno che non conosce il tuo bac...  <start> if someone who doesn't know your backg...\n",
       "340430  <start> senza dubbio esiste in questo mondo pr...  <start> doubtless there exists in this world p...\n",
       "\n",
       "[340431 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang['Italian'] = lang['Italian'].apply(preprocess_sentence)\n",
    "lang['English'] = lang['English'].apply(preprocess_sentence)\n",
    "lang.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jue4aBIvZtrj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDFaALFPr6Na"
   },
   "outputs": [],
   "source": [
    "lang.to_pickle('/content/drive/My Drive/26. Attention Models (italian to english )/text_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8RDrP4xKabR"
   },
   "source": [
    "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A45uc0JILMlV"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lx_5NA24KzRp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,enc_units,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.inp_vocab_size  = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = Embedding(input_dim = self.inp_vocab_size,output_dim = self.embedding_size,input_length = self.input_length, mask_zero = 0, name = 'embedding_layer')\n",
    "        self.lstm = LSTM(self.enc_units , return_sequences = True , return_state = True)\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "     \n",
    "      input_sentence = self.embedding(input_sequence)\n",
    "      lstm_output,state_h,state_c = self.lstm(input_sentence,initial_state=states)\n",
    "\n",
    "      return lstm_output,state_h,state_c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state shape is [32,lstm_units], cell state shape is [32,lstm_units]\n",
    "\n",
    "      '''\n",
    "      self.batch_size = batch_size\n",
    "      return (tf.zeros([batch_size,self.enc_units]),\n",
    "             tf.zeros([batch_size,self.enc_units]))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ub9aN-hK244"
   },
   "source": [
    "<font color='cyan'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wRoe65b9LB0D",
    "outputId": "2120ceed-c9a9-433c-b384-e4dcadcaac2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ab5SNdPZLlur"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "\n",
    "\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "    super(Attention,self).__init__()\n",
    "    self.scoring_function = scoring_function\n",
    "# Please go through the reference notebook and research paper to complete the scoring functions\n",
    "\n",
    "    if self.scoring_function=='dot':\n",
    "      pass  \n",
    "    if scoring_function == 'general':\n",
    "    # Intialize variables needed for General score function here\n",
    "      self.W1 = tf.keras.layers.Dense(att_units)\n",
    "      pass\n",
    "    elif scoring_function == 'concat':\n",
    "    # Intialize variables needed for Concat score function here\n",
    "      self.W1 = tf.keras.layers.Dense(att_units)\n",
    "      self.W2 = tf.keras.layers.Dense(att_units)\n",
    "      self.V = tf.keras.layers.Dense(1)\n",
    "      pass\n",
    "\n",
    "    \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    \n",
    "    if self.scoring_function == 'dot':\n",
    "    # Implement Dot score function here\n",
    "      query_with_time_axis = tf.expand_dims(decoder_hidden_state,-1)  ## Adding one dimension at the end\n",
    "      score = tf.matmul(encoder_output,query_with_time_axis) \n",
    "      attention_weight = tf.nn.softmax(score,axis=1)\n",
    "      context_vector = attention_weight*encoder_output\n",
    "      context_vector = tf.reduce_sum(context_vector,axis=1)\n",
    "      pass\n",
    "\n",
    "    if self.scoring_function == 'general':\n",
    "      #Implement General score function \n",
    "      query_with_time_axis = tf.expand_dims(decoder_hidden_state,-1)\n",
    "      score = self.W1(encoder_output)\n",
    "      score = tf.matmul(score,query_with_time_axis)\n",
    "      attention_weight = tf.nn.softmax(score,axis=1)\n",
    "      context_vector = attention_weight*encoder_output\n",
    "      context_vector = tf.reduce_sum(context_vector,axis=1)\n",
    "\n",
    "      \n",
    "      pass\n",
    "\n",
    "    elif self.scoring_function == 'concat':\n",
    "    # Implement General score function here\n",
    "\n",
    "      query_with_time_axis = tf.expand_dims(decoder_hidden_state,1)\n",
    "      score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(encoder_output)))\n",
    "      attention_weight = tf.nn.softmax(score,axis=1)\n",
    "      context_vector = attention_weight* encoder_output\n",
    "      context_vector = tf.reduce_sum(context_vector,axis=1)\n",
    "\n",
    "      pass\n",
    "\n",
    "    \n",
    "    return context_vector,attention_weight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ExQDlxI9LuqK"
   },
   "source": [
    "<font color='cyan'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "51x50h_TLrl9",
    "outputId": "f3f7f250-815d-4383-b7b6-e5c35c53d297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_attention(scoring_fun):\n",
    "    input_length=10\n",
    "    vocab_size=10\n",
    "    batch_size=16\n",
    "    att_units=32\n",
    "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
    "    attention=Attention(scoring_fun,att_units)\n",
    "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
    "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
    "    return True\n",
    "print(grader_check_attention('dot'))\n",
    "print(grader_check_attention('general'))\n",
    "print(grader_check_attention('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ic-FNEbfL2DN"
   },
   "source": [
    "<font color='blue'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      super(OneStepDecoder,self).__init__()\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      self.embedding = tf.keras.layers.Embedding(tar_vocab_size,embedding_dim)\n",
    "      self.lstm = tf.keras.layers.LSTM(dec_units,\n",
    "                                   return_state=True,\n",
    "                                   return_sequences = True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "      \n",
    "      self.dense = tf.keras.layers.Dense(tar_vocab_size)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "      ##Used for attention model\n",
    "      self.attention = Attention(score_fun,att_units)\n",
    "\n",
    "\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(1,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    \n",
    "    output = self.embedding(input_to_decoder)\n",
    "    context_vector,attention_weight = self.attention.call(state_h,encoder_output)\n",
    "    concatenated = tf.concat([tf.expand_dims(context_vector, 1), output], axis=-1)\n",
    "    decoder_output,state_h,state_c =  self.lstm(concatenated,initial_state = [state_h,state_c])\n",
    "    decoder_output = tf.reshape(decoder_output, (-1, decoder_output.shape[2]))\n",
    "    output = self.dense(decoder_output)\n",
    "\n",
    "    return output,state_h,state_c,attention_weight,context_vector\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_I8I4EIMAXq"
   },
   "source": [
    "<font color='cyan'>**Grader function - 3**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "uLEXhChnMC1k",
    "outputId": "cc04d7ea-832a-4ff6-ae32-0b47939858ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_onestepdecoder(score_fun):\n",
    "    vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    onestepdecoder=OneStepDecoder(vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
    "\n",
    "    assert(output.shape==(batch_size,vocab_size))\n",
    "    assert(state_h.shape==(batch_size,dec_units))\n",
    "    assert(state_c.shape==(batch_size,dec_units))\n",
    "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
    "    assert(context_vector.shape==(batch_size,dec_units))\n",
    "    return True\n",
    "    \n",
    "print(grader_onestepdecoder('dot'))\n",
    "print(grader_onestepdecoder('general'))\n",
    "print(grader_onestepdecoder('concat'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units):\n",
    "      super(Decoder,self).__init__()\n",
    "      self.vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.output_length = output_length\n",
    "      self.score_fun = score_fun\n",
    "      self.dec_units=dec_units\n",
    "      self.att_units = att_units\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      self.onestepdecoder = OneStepDecoder(self.vocab_size, self.embedding_dim, self.output_length, self.dec_units ,self.score_fun ,self.att_units)\n",
    "\n",
    "  \n",
    "    @tf.function   \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        all_output = tf.TensorArray(tf.float32,size=input_to_decoder.shape[1],name='output_arrays')\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "          \n",
    "          # Call onestepdecoder for each token in decoder_input\n",
    "         \n",
    "          output,decoder_hidden_state ,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder.call(input_to_decoder[:,timestep:timestep+1], encoder_output,decoder_hidden_state,decoder_cell_state)\n",
    "          # Store the output in tensorarray\n",
    "          \n",
    "          all_output = all_output.write(timestep,output)\n",
    "\n",
    "        # Return the tensor array\n",
    "        all_output = tf.transpose(all_output.stack(),[1,0,2])\n",
    "\n",
    "        return all_output\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxrL-P8bMJH6"
   },
   "source": [
    "<font color='cyan'>**Grader function - 4**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "rtbx6onFMJXb",
    "outputId": "95063970-941c-49da-8dc2-3927e5aff073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder(score_fun):\n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    output_length=11\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,output_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    \n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units)\n",
    "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
    "    assert(output.shape==(batch_size,output_length,out_vocab_size))\n",
    "    return True\n",
    "print(grader_decoder('dot'))\n",
    "print(grader_decoder('general'))\n",
    "print(grader_decoder('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,input_vocab_size,embedding_size,lstm_size,inp_len,out_vocab_size,out_len, dec_unit ,score ,att_unit):\n",
    "    super().__init__()\n",
    "    #Intialize objects from encoder decoder\n",
    "    self.encoder = Encoder(inp_vocab_size=input_vocab_size,embedding_size=300,enc_units=lstm_size,input_length=inp_len)\n",
    "    self.decoder = Decoder(out_vocab_size=out_vocab_size,embedding_dim=300,output_length=out_len,dec_units=dec_unit,score_fun=score,att_units=att_unit)\n",
    "    # self.dense = tf.keras.layers.Dense(out_vocab_size, activation = 'softmax')\n",
    "    # self.input_vocab_size = input_vocab_size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  def call(self,data):\n",
    "    input ,output = data[0],data[1]\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    initital_state = self.encoder.initialize_states(64)\n",
    "    encoder_output,encoder_state_h,encoder_state_c = self.encoder(input,initital_state)\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "\n",
    "\n",
    "\n",
    "    decoder_output = self.decoder(output,encoder_output,encoder_state_h,encoder_state_c)\n",
    "    # return the decoder output\n",
    "    # output = self.dense(decoder_output)\n",
    "    return decoder_output \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY_3izrXMs8y"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgyWwZWeMxGQ"
   },
   "outputs": [],
   "source": [
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbP9jDuLqsoT"
   },
   "outputs": [],
   "source": [
    "## Making of data \n",
    "data = pd.read_pickle('/content/drive/My Drive/26. Attention Models (italian to english )/text_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWyMpaMMgQ6j"
   },
   "outputs": [],
   "source": [
    "data = data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "sONsrSWSQ4wF",
    "outputId": "a4c2bc2f-7250-4ee3-8cb7-778f1cc2587e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Italian</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; ciao ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; hi . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; corri ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; corra ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; correte ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; chi ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; who ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>&lt;start&gt; io sono d'accordo col suo piano . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i agree with his plan . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>&lt;start&gt; sono d'accordo col suo piano . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i agree with his plan . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>&lt;start&gt; mi sento gia meglio . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i already feel better . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>&lt;start&gt; io mi sento gia meglio . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i already feel better . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>&lt;start&gt; ho gia un piano . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i already have a plan . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Italian                                English\n",
       "0                                 <start> ciao ! <end>                     <start> hi . <end>\n",
       "1                                <start> corri ! <end>                    <start> run ! <end>\n",
       "2                                <start> corra ! <end>                    <start> run ! <end>\n",
       "3                              <start> correte ! <end>                    <start> run ! <end>\n",
       "4                                  <start> chi ? <end>                    <start> who ? <end>\n",
       "...                                                ...                                    ...\n",
       "99994  <start> io sono d'accordo col suo piano . <end>  <start> i agree with his plan . <end>\n",
       "99995     <start> sono d'accordo col suo piano . <end>  <start> i agree with his plan . <end>\n",
       "99996              <start> mi sento gia meglio . <end>  <start> i already feel better . <end>\n",
       "99997           <start> io mi sento gia meglio . <end>  <start> i already feel better . <end>\n",
       "99998                  <start> ho gia un piano . <end>  <start> i already have a plan . <end>\n",
       "\n",
       "[99999 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvM3Yj8sB_cr"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh0Cri5aB_h0"
   },
   "outputs": [],
   "source": [
    "input_data, inp_lang_tokenizer = tokenize(data['Italian'])\n",
    "target_data, targ_lang_tokenizer = tokenize(data['English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_AAeekA4G-y"
   },
   "outputs": [],
   "source": [
    "inp_lang_tokenizer.word_index['<start>'] = inp_lang_tokenizer.word_index['start']\n",
    "del inp_lang_tokenizer.word_index['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MoRSkZFeB_lR",
    "outputId": "1b6f42d5-d506-4d5e-ddff-c0fa17e2382b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 19)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_targ, max_length_inp = target_data.shape[1], input_data.shape[1]\n",
    "max_length_targ,max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UG6HiBlyB_fj",
    "outputId": "a4bfcb5d-dd62-4e37-95fe-3c52b9879851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 70000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_data, target_data, test_size=0.30)\n",
    "\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKVZkt_Z8Z19"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PDNFcW6YDYHq",
    "outputId": "8d631494-c459-4610-8a8e-4f84d94e363b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 19), (64, 9)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haXp_3niPclx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc_PZtiM74UB"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyRA5g4rmx6a"
   },
   "outputs": [],
   "source": [
    "!rm -rf logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FJs7xIQ_m1nm",
    "outputId": "af0b186e-05a8-44d7-cbd8-297e6dea58af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/drive/My Drive/26. Attention Models (italian to english )/logs’: File exists\n"
     ]
    }
   ],
   "source": [
    "c_path = \"/content/drive/My Drive/26. Attention Models (italian to english )/checkpoint\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=c_path,monitor='val_loss',verbose=1,save_weights_only=True)\n",
    "\n",
    "!mkdir \"/content/drive/My Drive/26. Attention Models (italian to english )/logs\"\n",
    "t_path = \"/content/drive/My Drive/26. Attention Models (italian to english )/logs\"\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=t_path,histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO1mvwGG72B5"
   },
   "outputs": [],
   "source": [
    "score_fun = 'dot'\n",
    "inp_vocab_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "out_vocab_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "att_units = 128\n",
    "input_length =19\n",
    "output_length = 9\n",
    "encoder_units = 128\n",
    "decoder_units = 128\n",
    "attention_units = 128\n",
    "embedding = 300\n",
    "model = encoder_decoder(inp_vocab_size,300,encoder_units,input_length,out_vocab_size,output_length,decoder_units,score_fun,attention_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBGdFgTrTEHF"
   },
   "outputs": [],
   "source": [
    "optimizer   = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction='none')\n",
    "model.compile(optimizer=optimizer, loss=loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vIHKq5E1rxIh",
    "outputId": "cdf31d3a-a80b-479d-f6e1-d9bed6b89ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Encoder object at 0x7fbcbc7d3518>\n",
      "<__main__.Decoder object at 0x7fbcbca8f438>\n"
     ]
    }
   ],
   "source": [
    "## Taking output from Class as layers of encoder and decoder \n",
    "print(model.layers[0]) ## We can get the output of encoder from layer1\n",
    "print(model.layers[1]) ##   We can get the output of decoder from layer2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAAuqKuosmXt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_dir = '/content/drive/My Drive/26. Attention Models (italian to english )/training_checkpoint'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=model.layers[0],\n",
    "                                 decoder=model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wl4EZcabtvI8"
   },
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden,enc_state = model.layers[0](inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions = model.layers[1](dec_input,enc_output,enc_hidden,enc_state)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = model.layers[0].trainable_variables + model.layers[1].trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fWb6dImQ_-dR",
    "outputId": "b0c48a3d-8249-4597-e297-32b1cf3af67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.4160\n",
      "Epoch 1 Batch 100 Loss 2.6696\n",
      "Epoch 1 Batch 200 Loss 2.6294\n",
      "Epoch 1 Batch 300 Loss 2.3739\n",
      "Epoch 1 Batch 400 Loss 2.2217\n",
      "Epoch 1 Batch 500 Loss 2.2432\n",
      "Epoch 1 Batch 600 Loss 2.3119\n",
      "Epoch 1 Batch 700 Loss 2.0976\n",
      "Epoch 1 Batch 800 Loss 2.0887\n",
      "Epoch 1 Batch 900 Loss 2.0439\n",
      "Epoch 1 Batch 1000 Loss 1.9560\n",
      "Epoch 1 Loss 2.3154\n",
      "Time taken for 1 epoch 179.93755888938904 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9942\n",
      "Epoch 2 Batch 100 Loss 1.9066\n",
      "Epoch 2 Batch 200 Loss 1.9704\n",
      "Epoch 2 Batch 300 Loss 1.9958\n",
      "Epoch 2 Batch 400 Loss 1.9673\n",
      "Epoch 2 Batch 500 Loss 1.9439\n",
      "Epoch 2 Batch 600 Loss 2.0024\n",
      "Epoch 2 Batch 700 Loss 1.8889\n",
      "Epoch 2 Batch 800 Loss 1.8449\n",
      "Epoch 2 Batch 900 Loss 1.7944\n",
      "Epoch 2 Batch 1000 Loss 1.7105\n",
      "Epoch 2 Loss 1.8920\n",
      "Time taken for 1 epoch 177.9980800151825 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7706\n",
      "Epoch 3 Batch 100 Loss 1.7130\n",
      "Epoch 3 Batch 200 Loss 1.6270\n",
      "Epoch 3 Batch 300 Loss 1.6106\n",
      "Epoch 3 Batch 400 Loss 1.5946\n",
      "Epoch 3 Batch 500 Loss 1.6546\n",
      "Epoch 3 Batch 600 Loss 1.4902\n",
      "Epoch 3 Batch 700 Loss 1.4678\n",
      "Epoch 3 Batch 800 Loss 1.5063\n",
      "Epoch 3 Batch 900 Loss 1.3584\n",
      "Epoch 3 Batch 1000 Loss 1.4504\n",
      "Epoch 3 Loss 1.5416\n",
      "Time taken for 1 epoch 178.77796602249146 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3119\n",
      "Epoch 4 Batch 100 Loss 1.3017\n",
      "Epoch 4 Batch 200 Loss 1.2722\n",
      "Epoch 4 Batch 300 Loss 1.4167\n",
      "Epoch 4 Batch 400 Loss 1.4004\n",
      "Epoch 4 Batch 500 Loss 1.1891\n",
      "Epoch 4 Batch 600 Loss 1.1711\n",
      "Epoch 4 Batch 700 Loss 1.1416\n",
      "Epoch 4 Batch 800 Loss 1.1194\n",
      "Epoch 4 Batch 900 Loss 1.1250\n",
      "Epoch 4 Batch 1000 Loss 1.1569\n",
      "Epoch 4 Loss 1.2289\n",
      "Time taken for 1 epoch 179.27159476280212 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0547\n",
      "Epoch 5 Batch 100 Loss 1.0279\n",
      "Epoch 5 Batch 200 Loss 1.1632\n",
      "Epoch 5 Batch 300 Loss 1.1190\n",
      "Epoch 5 Batch 400 Loss 1.0104\n",
      "Epoch 5 Batch 500 Loss 0.9413\n",
      "Epoch 5 Batch 600 Loss 1.0800\n",
      "Epoch 5 Batch 700 Loss 0.9149\n",
      "Epoch 5 Batch 800 Loss 0.9918\n",
      "Epoch 5 Batch 900 Loss 0.9357\n",
      "Epoch 5 Batch 1000 Loss 0.9051\n",
      "Epoch 5 Loss 0.9874\n",
      "Time taken for 1 epoch 179.0356101989746 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.8236\n",
      "Epoch 6 Batch 100 Loss 0.8515\n",
      "Epoch 6 Batch 200 Loss 0.8546\n",
      "Epoch 6 Batch 300 Loss 0.8665\n",
      "Epoch 6 Batch 400 Loss 0.8428\n",
      "Epoch 6 Batch 500 Loss 0.7694\n",
      "Epoch 6 Batch 600 Loss 0.7016\n",
      "Epoch 6 Batch 700 Loss 0.7502\n",
      "Epoch 6 Batch 800 Loss 0.7855\n",
      "Epoch 6 Batch 900 Loss 0.6630\n",
      "Epoch 6 Batch 1000 Loss 0.7606\n",
      "Epoch 6 Loss 0.7956\n",
      "Time taken for 1 epoch 178.6244921684265 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6852\n",
      "Epoch 7 Batch 100 Loss 0.6379\n",
      "Epoch 7 Batch 200 Loss 0.6012\n",
      "Epoch 7 Batch 300 Loss 0.6202\n",
      "Epoch 7 Batch 400 Loss 0.6002\n",
      "Epoch 7 Batch 500 Loss 0.6170\n",
      "Epoch 7 Batch 600 Loss 0.7236\n",
      "Epoch 7 Batch 700 Loss 0.6920\n",
      "Epoch 7 Batch 800 Loss 0.6145\n",
      "Epoch 7 Batch 900 Loss 0.5722\n",
      "Epoch 7 Batch 1000 Loss 0.5038\n",
      "Epoch 7 Loss 0.6358\n",
      "Time taken for 1 epoch 177.08115243911743 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.4706\n",
      "Epoch 8 Batch 100 Loss 0.5403\n",
      "Epoch 8 Batch 200 Loss 0.4993\n",
      "Epoch 8 Batch 300 Loss 0.5771\n",
      "Epoch 8 Batch 400 Loss 0.4672\n",
      "Epoch 8 Batch 500 Loss 0.4453\n",
      "Epoch 8 Batch 600 Loss 0.5345\n",
      "Epoch 8 Batch 700 Loss 0.4512\n",
      "Epoch 8 Batch 800 Loss 0.4841\n",
      "Epoch 8 Batch 900 Loss 0.5052\n",
      "Epoch 8 Batch 1000 Loss 0.4436\n",
      "Epoch 8 Loss 0.5042\n",
      "Time taken for 1 epoch 179.22889757156372 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4089\n",
      "Epoch 9 Batch 100 Loss 0.4068\n",
      "Epoch 9 Batch 200 Loss 0.3959\n",
      "Epoch 9 Batch 300 Loss 0.3856\n",
      "Epoch 9 Batch 400 Loss 0.3946\n",
      "Epoch 9 Batch 500 Loss 0.3900\n",
      "Epoch 9 Batch 600 Loss 0.4346\n",
      "Epoch 9 Batch 700 Loss 0.4645\n",
      "Epoch 9 Batch 800 Loss 0.3833\n",
      "Epoch 9 Batch 900 Loss 0.3619\n",
      "Epoch 9 Batch 1000 Loss 0.4291\n",
      "Epoch 9 Loss 0.4010\n",
      "Time taken for 1 epoch 178.09329962730408 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.3436\n",
      "Epoch 10 Batch 100 Loss 0.3058\n",
      "Epoch 10 Batch 200 Loss 0.3012\n",
      "Epoch 10 Batch 300 Loss 0.2962\n",
      "Epoch 10 Batch 400 Loss 0.2872\n",
      "Epoch 10 Batch 500 Loss 0.2326\n",
      "Epoch 10 Batch 600 Loss 0.3153\n",
      "Epoch 10 Batch 700 Loss 0.3378\n",
      "Epoch 10 Batch 800 Loss 0.3002\n",
      "Epoch 10 Batch 900 Loss 0.3634\n",
      "Epoch 10 Batch 1000 Loss 0.2592\n",
      "Epoch 10 Loss 0.3217\n",
      "Time taken for 1 epoch 176.5481641292572 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.3197\n",
      "Epoch 11 Batch 100 Loss 0.3080\n",
      "Epoch 11 Batch 200 Loss 0.2187\n",
      "Epoch 11 Batch 300 Loss 0.2741\n",
      "Epoch 11 Batch 400 Loss 0.2537\n",
      "Epoch 11 Batch 500 Loss 0.2861\n",
      "Epoch 11 Batch 600 Loss 0.2461\n",
      "Epoch 11 Batch 700 Loss 0.2865\n",
      "Epoch 11 Batch 800 Loss 0.2046\n",
      "Epoch 11 Batch 900 Loss 0.2696\n",
      "Epoch 11 Batch 1000 Loss 0.2479\n",
      "Epoch 11 Loss 0.2620\n",
      "Time taken for 1 epoch 181.16614246368408 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.2128\n",
      "Epoch 12 Batch 100 Loss 0.1885\n",
      "Epoch 12 Batch 200 Loss 0.1899\n",
      "Epoch 12 Batch 300 Loss 0.1768\n",
      "Epoch 12 Batch 400 Loss 0.2100\n",
      "Epoch 12 Batch 500 Loss 0.2169\n",
      "Epoch 12 Batch 600 Loss 0.2267\n",
      "Epoch 12 Batch 700 Loss 0.2073\n",
      "Epoch 12 Batch 800 Loss 0.2529\n",
      "Epoch 12 Batch 900 Loss 0.3189\n",
      "Epoch 12 Batch 1000 Loss 0.2253\n",
      "Epoch 12 Loss 0.2169\n",
      "Time taken for 1 epoch 178.56028699874878 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1297\n",
      "Epoch 13 Batch 100 Loss 0.1696\n",
      "Epoch 13 Batch 200 Loss 0.1744\n",
      "Epoch 13 Batch 300 Loss 0.1915\n",
      "Epoch 13 Batch 400 Loss 0.1709\n",
      "Epoch 13 Batch 500 Loss 0.1538\n",
      "Epoch 13 Batch 600 Loss 0.1764\n",
      "Epoch 13 Batch 700 Loss 0.1769\n",
      "Epoch 13 Batch 800 Loss 0.1864\n",
      "Epoch 13 Batch 900 Loss 0.1387\n",
      "Epoch 13 Batch 1000 Loss 0.1799\n",
      "Epoch 13 Loss 0.1825\n",
      "Time taken for 1 epoch 175.49189043045044 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1896\n",
      "Epoch 14 Batch 100 Loss 0.1701\n",
      "Epoch 14 Batch 200 Loss 0.1318\n",
      "Epoch 14 Batch 300 Loss 0.1327\n",
      "Epoch 14 Batch 400 Loss 0.1428\n",
      "Epoch 14 Batch 500 Loss 0.1298\n",
      "Epoch 14 Batch 600 Loss 0.1475\n",
      "Epoch 14 Batch 700 Loss 0.1955\n",
      "Epoch 14 Batch 800 Loss 0.1775\n",
      "Epoch 14 Batch 900 Loss 0.1866\n",
      "Epoch 14 Batch 1000 Loss 0.1629\n",
      "Epoch 14 Loss 0.1565\n",
      "Time taken for 1 epoch 171.65180683135986 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1440\n",
      "Epoch 15 Batch 100 Loss 0.1548\n",
      "Epoch 15 Batch 200 Loss 0.1110\n",
      "Epoch 15 Batch 300 Loss 0.1477\n",
      "Epoch 15 Batch 400 Loss 0.1338\n",
      "Epoch 15 Batch 500 Loss 0.1456\n",
      "Epoch 15 Batch 600 Loss 0.1740\n",
      "Epoch 15 Batch 700 Loss 0.1236\n",
      "Epoch 15 Batch 800 Loss 0.1460\n",
      "Epoch 15 Batch 900 Loss 0.1236\n",
      "Epoch 15 Batch 1000 Loss 0.1136\n",
      "Epoch 15 Loss 0.1362\n",
      "Time taken for 1 epoch 175.64721965789795 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1193\n",
      "Epoch 16 Batch 100 Loss 0.1329\n",
      "Epoch 16 Batch 200 Loss 0.1579\n",
      "Epoch 16 Batch 300 Loss 0.0940\n",
      "Epoch 16 Batch 400 Loss 0.0920\n",
      "Epoch 16 Batch 500 Loss 0.1395\n",
      "Epoch 16 Batch 600 Loss 0.1443\n",
      "Epoch 16 Batch 700 Loss 0.1510\n",
      "Epoch 16 Batch 800 Loss 0.1165\n",
      "Epoch 16 Batch 900 Loss 0.1000\n",
      "Epoch 16 Batch 1000 Loss 0.1236\n",
      "Epoch 16 Loss 0.1197\n",
      "Time taken for 1 epoch 175.97719979286194 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0850\n",
      "Epoch 17 Batch 100 Loss 0.1151\n",
      "Epoch 17 Batch 200 Loss 0.1058\n",
      "Epoch 17 Batch 300 Loss 0.1177\n",
      "Epoch 17 Batch 400 Loss 0.0858\n",
      "Epoch 17 Batch 500 Loss 0.0859\n",
      "Epoch 17 Batch 600 Loss 0.0898\n",
      "Epoch 17 Batch 700 Loss 0.1249\n",
      "Epoch 17 Batch 800 Loss 0.1562\n",
      "Epoch 17 Batch 900 Loss 0.1132\n",
      "Epoch 17 Batch 1000 Loss 0.1340\n",
      "Epoch 17 Loss 0.1072\n",
      "Time taken for 1 epoch 177.48211288452148 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0885\n",
      "Epoch 18 Batch 100 Loss 0.0843\n",
      "Epoch 18 Batch 200 Loss 0.1009\n",
      "Epoch 18 Batch 300 Loss 0.1237\n",
      "Epoch 18 Batch 400 Loss 0.1040\n",
      "Epoch 18 Batch 500 Loss 0.1145\n",
      "Epoch 18 Batch 600 Loss 0.1105\n",
      "Epoch 18 Batch 700 Loss 0.1213\n",
      "Epoch 18 Batch 800 Loss 0.0899\n",
      "Epoch 18 Batch 900 Loss 0.1270\n",
      "Epoch 18 Batch 1000 Loss 0.1226\n",
      "Epoch 18 Loss 0.0964\n",
      "Time taken for 1 epoch 177.34772729873657 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1071\n",
      "Epoch 19 Batch 100 Loss 0.0766\n",
      "Epoch 19 Batch 200 Loss 0.1154\n",
      "Epoch 19 Batch 300 Loss 0.0844\n",
      "Epoch 19 Batch 400 Loss 0.0836\n",
      "Epoch 19 Batch 500 Loss 0.0806\n",
      "Epoch 19 Batch 600 Loss 0.1024\n",
      "Epoch 19 Batch 700 Loss 0.0889\n",
      "Epoch 19 Batch 800 Loss 0.0896\n",
      "Epoch 19 Batch 900 Loss 0.0761\n",
      "Epoch 19 Batch 1000 Loss 0.0751\n",
      "Epoch 19 Loss 0.0884\n",
      "Time taken for 1 epoch 178.76973295211792 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0529\n",
      "Epoch 20 Batch 100 Loss 0.0671\n",
      "Epoch 20 Batch 200 Loss 0.1085\n",
      "Epoch 20 Batch 300 Loss 0.0818\n",
      "Epoch 20 Batch 400 Loss 0.0794\n",
      "Epoch 20 Batch 500 Loss 0.1089\n",
      "Epoch 20 Batch 600 Loss 0.0987\n",
      "Epoch 20 Batch 700 Loss 0.1213\n",
      "Epoch 20 Batch 800 Loss 0.0958\n",
      "Epoch 20 Batch 900 Loss 0.0763\n",
      "Epoch 20 Batch 1000 Loss 0.0664\n",
      "Epoch 20 Loss 0.0811\n",
      "Time taken for 1 epoch 176.25465559959412 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = model.layers[0].initialize_states(64)\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkEY7SsBMtrC"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention_weight,sentence, predicted_sentence):\n",
    "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention_weight, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MP3kLZoPMvSu"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  \n",
    "\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence                                              \n",
    "  '''\n",
    "  attention_plot = np.zeros((output_length,input_length))\n",
    "  preprocessed_sentence = preprocess_sentence(input_sentence)\n",
    "  \n",
    "  print(preprocessed_sentence)\n",
    "\n",
    "  inputs = [inp_lang_tokenizer.word_index[i] for i in preprocessed_sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=input_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  enc_out, enc_hidden,enc_current = model.layers[0](inputs, [tf.zeros((1, encoder_units)),tf.zeros((1, encoder_units))])\n",
    "\n",
    "  \n",
    "  dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] , 0)\n",
    "\n",
    "  for t in range(output_length):\n",
    "    predictions,state_h,state_c, attention_weights,context_vector =model.layers[1].onestepdecoder(dec_input,\n",
    "                                                         enc_out,enc_hidden,enc_current)\n",
    "                                                        \n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    print(predicted_id)\n",
    "\n",
    "    result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      return result, preprocessed_sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, preprocessed_sentence, attention_plot\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I81e7Dsb30Ka"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  print('Input: %s' % (sent))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sent.split(' '))]\n",
    "  plot_attention(attention_plot, sent.split(' '), result.split(' '))\n",
    "\n",
    "  return sentence,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "colab_type": "code",
    "id": "gIKv1_jsg7l5",
    "outputId": "5729c4fd-87b4-4e13-bef0-ff4222e8f1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> ciao <end>\n",
      "1110\n",
      "hi \n",
      "2\n",
      "hi end \n",
      "Input: <start> ciao <end>\n",
      "Predicted translation: hi end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent,pred = translate('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "6aSBpD7HGcpP",
    "outputId": "65eac15b-975c-4f10-f506-d23f9d169453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_lang_tokenizer.word_index['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmxIVOOQPWMu"
   },
   "source": [
    "<font color='blue'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "0iHiLdROM23l",
    "outputId": "adcb8a60-dab2-4515-8ccb-5ff8dc10d6e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "#Create an object of your custom model.                                         \n",
    "#Compile and train your model on dot scoring function.\n",
    "# Visualize few sentences randomly in Test data                                 \n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "                                                                                \n",
    "#Sample example                                                                 \n",
    "import nltk.translate.bleu_score as bleu\n",
    "score = 0\n",
    "for i in range(1000):\n",
    "  score = score + bleu.sentence_bleu(data['English'].iloc[i].split(' '), pred)\n",
    "\n",
    "print(f'Final Bleu score :{score/1000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "dFMqbG8U0-w5",
    "outputId": "d049f3cd-9262-48fc-b46b-cb9b0252b697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bleu score :0.43597427246383813\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Bleu score :{score/1000}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CgXTSVfWFTB"
   },
   "source": [
    "<h3> Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pYeay9YVvz5"
   },
   "source": [
    "<h4> Score function dot is giving bleu score of 0.44 for 1000 sentences with loss of 0.08 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWg2ferDQvT3"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Rh9_w79M5JO"
   },
   "outputs": [],
   "source": [
    "#Compile and train your model on general scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oojK7u9wV44N"
   },
   "outputs": [],
   "source": [
    "score_fun = 'general'\n",
    "inp_vocab_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "out_vocab_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "att_units = 128\n",
    "input_length =19\n",
    "output_length = 9\n",
    "encoder_units = 128\n",
    "decoder_units = 128\n",
    "attention_units = 128\n",
    "embedding = 300\n",
    "model2 = encoder_decoder(inp_vocab_size,300,encoder_units,input_length,out_vocab_size,output_length,decoder_units,score_fun,attention_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBFEg9MwV47Y"
   },
   "outputs": [],
   "source": [
    "optimizer   = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction='none')\n",
    "model2.compile(optimizer=optimizer, loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpYD02MYV4_I"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_dir2 = '/content/drive/My Drive/26. Attention Models (italian to english )/training_checkpoint2'\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt\")\n",
    "checkpoint2 = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=model2.layers[0],\n",
    "                                 decoder=model2.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wt3t1x_YHeJ"
   },
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden,enc_state = model2.layers[0](inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions = model2.layers[1](dec_input,enc_output,enc_hidden,enc_state)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = model2.layers[0].trainable_variables + model2.layers[1].trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nfwLj4XJV5Bf",
    "outputId": "78ff0ceb-6a2c-44c4-a829-3bd698607b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.7968\n",
      "Epoch 1 Batch 100 Loss 1.8221\n",
      "Epoch 1 Batch 200 Loss 1.7937\n",
      "Epoch 1 Batch 300 Loss 1.8566\n",
      "Epoch 1 Batch 400 Loss 1.7431\n",
      "Epoch 1 Batch 500 Loss 1.6255\n",
      "Epoch 1 Batch 600 Loss 1.6939\n",
      "Epoch 1 Batch 700 Loss 1.7127\n",
      "Epoch 1 Batch 800 Loss 1.5821\n",
      "Epoch 1 Batch 900 Loss 1.4251\n",
      "Epoch 1 Batch 1000 Loss 1.4663\n",
      "Epoch 1 Loss 1.6741\n",
      "Time taken for 1 epoch 163.19747352600098 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.3652\n",
      "Epoch 2 Batch 100 Loss 1.4298\n",
      "Epoch 2 Batch 200 Loss 1.2699\n",
      "Epoch 2 Batch 300 Loss 1.3220\n",
      "Epoch 2 Batch 400 Loss 1.4221\n",
      "Epoch 2 Batch 500 Loss 1.3607\n",
      "Epoch 2 Batch 600 Loss 1.3553\n",
      "Epoch 2 Batch 700 Loss 1.4359\n",
      "Epoch 2 Batch 800 Loss 1.2377\n",
      "Epoch 2 Batch 900 Loss 1.1956\n",
      "Epoch 2 Batch 1000 Loss 1.3124\n",
      "Epoch 2 Loss 1.3062\n",
      "Time taken for 1 epoch 162.84054374694824 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0930\n",
      "Epoch 3 Batch 100 Loss 1.1443\n",
      "Epoch 3 Batch 200 Loss 1.1314\n",
      "Epoch 3 Batch 300 Loss 1.1586\n",
      "Epoch 3 Batch 400 Loss 1.0120\n",
      "Epoch 3 Batch 500 Loss 1.1037\n",
      "Epoch 3 Batch 600 Loss 1.0450\n",
      "Epoch 3 Batch 700 Loss 0.9986\n",
      "Epoch 3 Batch 800 Loss 1.0992\n",
      "Epoch 3 Batch 900 Loss 1.0001\n",
      "Epoch 3 Batch 1000 Loss 1.0585\n",
      "Epoch 3 Loss 1.0618\n",
      "Time taken for 1 epoch 163.11387467384338 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8741\n",
      "Epoch 4 Batch 100 Loss 0.9248\n",
      "Epoch 4 Batch 200 Loss 0.9402\n",
      "Epoch 4 Batch 300 Loss 0.8488\n",
      "Epoch 4 Batch 400 Loss 0.9066\n",
      "Epoch 4 Batch 500 Loss 0.8590\n",
      "Epoch 4 Batch 600 Loss 0.8019\n",
      "Epoch 4 Batch 700 Loss 0.8105\n",
      "Epoch 4 Batch 800 Loss 0.8431\n",
      "Epoch 4 Batch 900 Loss 0.7893\n",
      "Epoch 4 Batch 1000 Loss 0.7213\n",
      "Epoch 4 Loss 0.8634\n",
      "Time taken for 1 epoch 162.08947324752808 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.6852\n",
      "Epoch 5 Batch 100 Loss 0.6900\n",
      "Epoch 5 Batch 200 Loss 0.7994\n",
      "Epoch 5 Batch 300 Loss 0.8032\n",
      "Epoch 5 Batch 400 Loss 0.7822\n",
      "Epoch 5 Batch 500 Loss 0.7225\n",
      "Epoch 5 Batch 600 Loss 0.6567\n",
      "Epoch 5 Batch 700 Loss 0.7278\n",
      "Epoch 5 Batch 800 Loss 0.6512\n",
      "Epoch 5 Batch 900 Loss 0.6574\n",
      "Epoch 5 Batch 1000 Loss 0.6916\n",
      "Epoch 5 Loss 0.6923\n",
      "Time taken for 1 epoch 162.7072036266327 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.5593\n",
      "Epoch 6 Batch 100 Loss 0.5697\n",
      "Epoch 6 Batch 200 Loss 0.6382\n",
      "Epoch 6 Batch 300 Loss 0.6345\n",
      "Epoch 6 Batch 400 Loss 0.7065\n",
      "Epoch 6 Batch 500 Loss 0.5809\n",
      "Epoch 6 Batch 600 Loss 0.5631\n",
      "Epoch 6 Batch 700 Loss 0.4888\n",
      "Epoch 6 Batch 800 Loss 0.5713\n",
      "Epoch 6 Batch 900 Loss 0.5476\n",
      "Epoch 6 Batch 1000 Loss 0.5198\n",
      "Epoch 6 Loss 0.5491\n",
      "Time taken for 1 epoch 162.17881989479065 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4300\n",
      "Epoch 7 Batch 100 Loss 0.4246\n",
      "Epoch 7 Batch 200 Loss 0.4547\n",
      "Epoch 7 Batch 300 Loss 0.4344\n",
      "Epoch 7 Batch 400 Loss 0.3626\n",
      "Epoch 7 Batch 500 Loss 0.4331\n",
      "Epoch 7 Batch 600 Loss 0.4468\n",
      "Epoch 7 Batch 700 Loss 0.4879\n",
      "Epoch 7 Batch 800 Loss 0.4863\n",
      "Epoch 7 Batch 900 Loss 0.4222\n",
      "Epoch 7 Batch 1000 Loss 0.3697\n",
      "Epoch 7 Loss 0.4357\n",
      "Time taken for 1 epoch 163.1062617301941 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.3294\n",
      "Epoch 8 Batch 100 Loss 0.2881\n",
      "Epoch 8 Batch 200 Loss 0.3677\n",
      "Epoch 8 Batch 300 Loss 0.3597\n",
      "Epoch 8 Batch 400 Loss 0.3123\n",
      "Epoch 8 Batch 500 Loss 0.3170\n",
      "Epoch 8 Batch 600 Loss 0.3259\n",
      "Epoch 8 Batch 700 Loss 0.3336\n",
      "Epoch 8 Batch 800 Loss 0.3783\n",
      "Epoch 8 Batch 900 Loss 0.3722\n",
      "Epoch 8 Batch 1000 Loss 0.4023\n",
      "Epoch 8 Loss 0.3492\n",
      "Time taken for 1 epoch 162.60294103622437 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2600\n",
      "Epoch 9 Batch 100 Loss 0.2576\n",
      "Epoch 9 Batch 200 Loss 0.2257\n",
      "Epoch 9 Batch 300 Loss 0.2736\n",
      "Epoch 9 Batch 400 Loss 0.2651\n",
      "Epoch 9 Batch 500 Loss 0.2849\n",
      "Epoch 9 Batch 600 Loss 0.2914\n",
      "Epoch 9 Batch 700 Loss 0.2555\n",
      "Epoch 9 Batch 800 Loss 0.2470\n",
      "Epoch 9 Batch 900 Loss 0.2716\n",
      "Epoch 9 Batch 1000 Loss 0.3070\n",
      "Epoch 9 Loss 0.2841\n",
      "Time taken for 1 epoch 161.11341643333435 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2018\n",
      "Epoch 10 Batch 100 Loss 0.3013\n",
      "Epoch 10 Batch 200 Loss 0.2779\n",
      "Epoch 10 Batch 300 Loss 0.2219\n",
      "Epoch 10 Batch 400 Loss 0.2582\n",
      "Epoch 10 Batch 500 Loss 0.2574\n",
      "Epoch 10 Batch 600 Loss 0.2125\n",
      "Epoch 10 Batch 700 Loss 0.2226\n",
      "Epoch 10 Batch 800 Loss 0.2133\n",
      "Epoch 10 Batch 900 Loss 0.2577\n",
      "Epoch 10 Batch 1000 Loss 0.2449\n",
      "Epoch 10 Loss 0.2344\n",
      "Time taken for 1 epoch 161.4602153301239 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1894\n",
      "Epoch 11 Batch 100 Loss 0.2048\n",
      "Epoch 11 Batch 200 Loss 0.1659\n",
      "Epoch 11 Batch 300 Loss 0.2554\n",
      "Epoch 11 Batch 400 Loss 0.1737\n",
      "Epoch 11 Batch 500 Loss 0.1905\n",
      "Epoch 11 Batch 600 Loss 0.1533\n",
      "Epoch 11 Batch 700 Loss 0.2030\n",
      "Epoch 11 Batch 800 Loss 0.2584\n",
      "Epoch 11 Batch 900 Loss 0.1835\n",
      "Epoch 11 Batch 1000 Loss 0.1351\n",
      "Epoch 11 Loss 0.1973\n",
      "Time taken for 1 epoch 161.95968174934387 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1798\n",
      "Epoch 12 Batch 100 Loss 0.1545\n",
      "Epoch 12 Batch 200 Loss 0.1667\n",
      "Epoch 12 Batch 300 Loss 0.1135\n",
      "Epoch 12 Batch 400 Loss 0.1331\n",
      "Epoch 12 Batch 500 Loss 0.1699\n",
      "Epoch 12 Batch 600 Loss 0.1581\n",
      "Epoch 12 Batch 700 Loss 0.2209\n",
      "Epoch 12 Batch 800 Loss 0.2538\n",
      "Epoch 12 Batch 900 Loss 0.1360\n",
      "Epoch 12 Batch 1000 Loss 0.1999\n",
      "Epoch 12 Loss 0.1683\n",
      "Time taken for 1 epoch 161.95523810386658 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1299\n",
      "Epoch 13 Batch 100 Loss 0.1470\n",
      "Epoch 13 Batch 200 Loss 0.1807\n",
      "Epoch 13 Batch 300 Loss 0.1922\n",
      "Epoch 13 Batch 400 Loss 0.1396\n",
      "Epoch 13 Batch 500 Loss 0.1478\n",
      "Epoch 13 Batch 600 Loss 0.1160\n",
      "Epoch 13 Batch 700 Loss 0.1068\n",
      "Epoch 13 Batch 800 Loss 0.1650\n",
      "Epoch 13 Batch 900 Loss 0.2006\n",
      "Epoch 13 Batch 1000 Loss 0.1674\n",
      "Epoch 13 Loss 0.1453\n",
      "Time taken for 1 epoch 162.05851817131042 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0954\n",
      "Epoch 14 Batch 100 Loss 0.0980\n",
      "Epoch 14 Batch 200 Loss 0.1543\n",
      "Epoch 14 Batch 300 Loss 0.1389\n",
      "Epoch 14 Batch 400 Loss 0.1282\n",
      "Epoch 14 Batch 500 Loss 0.1182\n",
      "Epoch 14 Batch 600 Loss 0.1184\n",
      "Epoch 14 Batch 700 Loss 0.1602\n",
      "Epoch 14 Batch 800 Loss 0.1302\n",
      "Epoch 14 Batch 900 Loss 0.1638\n",
      "Epoch 14 Batch 1000 Loss 0.1515\n",
      "Epoch 14 Loss 0.1281\n",
      "Time taken for 1 epoch 161.7855908870697 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1004\n",
      "Epoch 15 Batch 100 Loss 0.0865\n",
      "Epoch 15 Batch 200 Loss 0.1196\n",
      "Epoch 15 Batch 300 Loss 0.1022\n",
      "Epoch 15 Batch 400 Loss 0.1086\n",
      "Epoch 15 Batch 500 Loss 0.1168\n",
      "Epoch 15 Batch 600 Loss 0.1104\n",
      "Epoch 15 Batch 700 Loss 0.1311\n",
      "Epoch 15 Batch 800 Loss 0.0776\n",
      "Epoch 15 Batch 900 Loss 0.1565\n",
      "Epoch 15 Batch 1000 Loss 0.1318\n",
      "Epoch 15 Loss 0.1134\n",
      "Time taken for 1 epoch 163.47854447364807 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0702\n",
      "Epoch 16 Batch 100 Loss 0.1170\n",
      "Epoch 16 Batch 200 Loss 0.0906\n",
      "Epoch 16 Batch 300 Loss 0.0901\n",
      "Epoch 16 Batch 400 Loss 0.1039\n",
      "Epoch 16 Batch 500 Loss 0.0800\n",
      "Epoch 16 Batch 600 Loss 0.0948\n",
      "Epoch 16 Batch 700 Loss 0.0972\n",
      "Epoch 16 Batch 800 Loss 0.1008\n",
      "Epoch 16 Batch 900 Loss 0.1194\n",
      "Epoch 16 Batch 1000 Loss 0.1159\n",
      "Epoch 16 Loss 0.1021\n",
      "Time taken for 1 epoch 162.49521327018738 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0770\n",
      "Epoch 17 Batch 100 Loss 0.0804\n",
      "Epoch 17 Batch 200 Loss 0.0915\n",
      "Epoch 17 Batch 300 Loss 0.0957\n",
      "Epoch 17 Batch 400 Loss 0.0520\n",
      "Epoch 17 Batch 500 Loss 0.0979\n",
      "Epoch 17 Batch 600 Loss 0.0840\n",
      "Epoch 17 Batch 700 Loss 0.1074\n",
      "Epoch 17 Batch 800 Loss 0.1327\n",
      "Epoch 17 Batch 900 Loss 0.0982\n",
      "Epoch 17 Batch 1000 Loss 0.0985\n",
      "Epoch 17 Loss 0.0931\n",
      "Time taken for 1 epoch 162.30104613304138 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1071\n",
      "Epoch 18 Batch 100 Loss 0.0415\n",
      "Epoch 18 Batch 200 Loss 0.0626\n",
      "Epoch 18 Batch 300 Loss 0.0861\n",
      "Epoch 18 Batch 400 Loss 0.0583\n",
      "Epoch 18 Batch 500 Loss 0.0631\n",
      "Epoch 18 Batch 600 Loss 0.0714\n",
      "Epoch 18 Batch 700 Loss 0.0851\n",
      "Epoch 18 Batch 800 Loss 0.0806\n",
      "Epoch 18 Batch 900 Loss 0.0855\n",
      "Epoch 18 Batch 1000 Loss 0.1224\n",
      "Epoch 18 Loss 0.0856\n",
      "Time taken for 1 epoch 161.3470561504364 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0764\n",
      "Epoch 19 Batch 100 Loss 0.0663\n",
      "Epoch 19 Batch 200 Loss 0.0982\n",
      "Epoch 19 Batch 300 Loss 0.0669\n",
      "Epoch 19 Batch 400 Loss 0.0832\n",
      "Epoch 19 Batch 500 Loss 0.0542\n",
      "Epoch 19 Batch 600 Loss 0.0966\n",
      "Epoch 19 Batch 700 Loss 0.0550\n",
      "Epoch 19 Batch 800 Loss 0.0755\n",
      "Epoch 19 Batch 900 Loss 0.0670\n",
      "Epoch 19 Batch 1000 Loss 0.0690\n",
      "Epoch 19 Loss 0.0789\n",
      "Time taken for 1 epoch 161.34625625610352 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0699\n",
      "Epoch 20 Batch 100 Loss 0.0394\n",
      "Epoch 20 Batch 200 Loss 0.0581\n",
      "Epoch 20 Batch 300 Loss 0.0508\n",
      "Epoch 20 Batch 400 Loss 0.0848\n",
      "Epoch 20 Batch 500 Loss 0.0547\n",
      "Epoch 20 Batch 600 Loss 0.0678\n",
      "Epoch 20 Batch 700 Loss 0.1075\n",
      "Epoch 20 Batch 800 Loss 0.1131\n",
      "Epoch 20 Batch 900 Loss 0.0552\n",
      "Epoch 20 Batch 1000 Loss 0.1074\n",
      "Epoch 20 Loss 0.0741\n",
      "Time taken for 1 epoch 164.40488529205322 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = model2.layers[0].initialize_states(64)\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint2.save(file_prefix = checkpoint_prefix2)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6Snm7yDV5Hg"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention_weight,sentence, predicted_sentence):\n",
    "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention_weight, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RzNc_WZV5Ef"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  \n",
    "\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence                                              \n",
    "  '''\n",
    "  attention_plot = np.zeros((output_length,input_length))\n",
    "  preprocessed_sentence = preprocess_sentence(input_sentence)\n",
    "  \n",
    "  print(preprocessed_sentence)\n",
    "\n",
    "  inputs = [inp_lang_tokenizer.word_index[i] for i in preprocessed_sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=input_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  enc_out, enc_hidden,enc_current = model2.layers[0](inputs, [tf.zeros((1, encoder_units)),tf.zeros((1, encoder_units))])\n",
    "\n",
    "  \n",
    "  dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] , 0)\n",
    "\n",
    "  for t in range(output_length):\n",
    "    predictions,state_h,state_c, attention_weights,context_vector =model2.layers[1].onestepdecoder(dec_input,\n",
    "                                                         enc_out,enc_hidden,enc_current)\n",
    "                                                        \n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    print(predicted_id)\n",
    "\n",
    "    result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      return result, preprocessed_sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, preprocessed_sentence, attention_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZGk-ZujLINL"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  print('Input: %s' % (sent))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sent.split(' '))]\n",
    "  plot_attention(attention_plot, sent.split(' '), result.split(' '))\n",
    "\n",
    "  return sentence,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "colab_type": "code",
    "id": "Zo5P22ykLIQA",
    "outputId": "ad6f5f6d-3241-4d14-9429-f04a15d3a1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> ciao <end>\n",
      "2589\n",
      "goodbye \n",
      "2\n",
      "goodbye end \n",
      "Input: <start> ciao <end>\n",
      "Predicted translation: goodbye end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent,pred = translate('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93-5RL_dLITa"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "score = 0\n",
    "for i in range(1000):\n",
    "  score = score + bleu.sentence_bleu(data['English'].iloc[i].split(' '), pred)\n",
    "\n",
    "final_score = score/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E4MuX7iCW9Zy",
    "outputId": "7c452081-dee8-489f-de28-db9b9a1eccb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bleu score : 0.4035820134\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Bleu score : {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ljq4b1bdWgrY"
   },
   "source": [
    "<h3> Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Sr_iRRaWdYi"
   },
   "source": [
    "<h4> Score function dot is giving bleu score of 0.41 for 1000 sentences with loss of 0.074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VB1jRUqZQ9AM"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kN9ZWViQNMB"
   },
   "outputs": [],
   "source": [
    "#Compile and train your model on concat scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff1lV0ITM6_p"
   },
   "outputs": [],
   "source": [
    "# Write your observations on each of the scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSwm_RnKXJAc"
   },
   "outputs": [],
   "source": [
    "score_fun = 'concat'\n",
    "inp_vocab_size = len(inp_lang_tokenizer.word_index) + 1\n",
    "out_vocab_size = len(targ_lang_tokenizer.word_index) + 1\n",
    "att_units = 128\n",
    "input_length =19\n",
    "output_length = 9\n",
    "encoder_units = 128\n",
    "decoder_units = 128\n",
    "attention_units = 128\n",
    "embedding = 300\n",
    "model3 = encoder_decoder(inp_vocab_size,300,encoder_units,input_length,out_vocab_size,output_length,decoder_units,score_fun,attention_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GYYtjn-XJDM"
   },
   "outputs": [],
   "source": [
    "optimizer   = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction='none')\n",
    "model3.compile(optimizer=optimizer, loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nSgxGv8XJIV"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_dir3= '/content/drive/My Drive/26. Attention Models (italian to english )/training_checkpoint'\n",
    "checkpoint_prefix3 = os.path.join(checkpoint_dir3, \"ckpt\")\n",
    "checkpoint3 = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=model3.layers[0],\n",
    "                                 decoder=model3.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9mcdRXhC7Qr"
   },
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden,enc_state = model3.layers[0](inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions = model3.layers[1](dec_input,enc_output,enc_hidden,enc_state)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = model3.layers[0].trainable_variables + model3.layers[1].trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ll32c7ZbXJLn",
    "outputId": "87ae97ac-9564-418e-f6d0-7321e7a99e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.1131\n",
      "Epoch 1 Batch 100 Loss 1.9314\n",
      "Epoch 1 Batch 200 Loss 1.9500\n",
      "Epoch 1 Batch 300 Loss 1.9493\n",
      "Epoch 1 Batch 400 Loss 1.9632\n",
      "Epoch 1 Batch 500 Loss 1.8059\n",
      "Epoch 1 Batch 600 Loss 1.7760\n",
      "Epoch 1 Batch 700 Loss 1.8158\n",
      "Epoch 1 Batch 800 Loss 1.7736\n",
      "Epoch 1 Batch 900 Loss 1.6640\n",
      "Epoch 1 Batch 1000 Loss 1.6322\n",
      "Epoch 1 Loss 1.8242\n",
      "Time taken for 1 epoch 200.8970696926117 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4983\n",
      "Epoch 2 Batch 100 Loss 1.5095\n",
      "Epoch 2 Batch 200 Loss 1.4773\n",
      "Epoch 2 Batch 300 Loss 1.5811\n",
      "Epoch 2 Batch 400 Loss 1.4559\n",
      "Epoch 2 Batch 500 Loss 1.5614\n",
      "Epoch 2 Batch 600 Loss 1.3068\n",
      "Epoch 2 Batch 700 Loss 1.4137\n",
      "Epoch 2 Batch 800 Loss 1.4599\n",
      "Epoch 2 Batch 900 Loss 1.2698\n",
      "Epoch 2 Batch 1000 Loss 1.3050\n",
      "Epoch 2 Loss 1.4344\n",
      "Time taken for 1 epoch 199.8168921470642 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1549\n",
      "Epoch 3 Batch 100 Loss 1.1672\n",
      "Epoch 3 Batch 200 Loss 1.1383\n",
      "Epoch 3 Batch 300 Loss 1.2165\n",
      "Epoch 3 Batch 400 Loss 1.0761\n",
      "Epoch 3 Batch 500 Loss 1.0542\n",
      "Epoch 3 Batch 600 Loss 1.1279\n",
      "Epoch 3 Batch 700 Loss 1.0224\n",
      "Epoch 3 Batch 800 Loss 1.0813\n",
      "Epoch 3 Batch 900 Loss 1.1576\n",
      "Epoch 3 Batch 1000 Loss 1.1303\n",
      "Epoch 3 Loss 1.1131\n",
      "Time taken for 1 epoch 198.56015253067017 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.9586\n",
      "Epoch 4 Batch 100 Loss 0.9168\n",
      "Epoch 4 Batch 200 Loss 1.0201\n",
      "Epoch 4 Batch 300 Loss 0.9507\n",
      "Epoch 4 Batch 400 Loss 0.8900\n",
      "Epoch 4 Batch 500 Loss 0.9702\n",
      "Epoch 4 Batch 600 Loss 0.9503\n",
      "Epoch 4 Batch 700 Loss 0.8156\n",
      "Epoch 4 Batch 800 Loss 0.8276\n",
      "Epoch 4 Batch 900 Loss 0.8351\n",
      "Epoch 4 Batch 1000 Loss 0.8490\n",
      "Epoch 4 Loss 0.8724\n",
      "Time taken for 1 epoch 198.8023645877838 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.6146\n",
      "Epoch 5 Batch 100 Loss 0.7741\n",
      "Epoch 5 Batch 200 Loss 0.7687\n",
      "Epoch 5 Batch 300 Loss 0.6445\n",
      "Epoch 5 Batch 400 Loss 0.6511\n",
      "Epoch 5 Batch 500 Loss 0.6826\n",
      "Epoch 5 Batch 600 Loss 0.6777\n",
      "Epoch 5 Batch 700 Loss 0.6231\n",
      "Epoch 5 Batch 800 Loss 0.7318\n",
      "Epoch 5 Batch 900 Loss 0.5223\n",
      "Epoch 5 Batch 1000 Loss 0.6809\n",
      "Epoch 5 Loss 0.6808\n",
      "Time taken for 1 epoch 197.36325120925903 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.5739\n",
      "Epoch 6 Batch 100 Loss 0.5471\n",
      "Epoch 6 Batch 200 Loss 0.4998\n",
      "Epoch 6 Batch 300 Loss 0.5584\n",
      "Epoch 6 Batch 400 Loss 0.5395\n",
      "Epoch 6 Batch 500 Loss 0.5273\n",
      "Epoch 6 Batch 600 Loss 0.5766\n",
      "Epoch 6 Batch 700 Loss 0.5351\n",
      "Epoch 6 Batch 800 Loss 0.6232\n",
      "Epoch 6 Batch 900 Loss 0.4725\n",
      "Epoch 6 Batch 1000 Loss 0.5039\n",
      "Epoch 6 Loss 0.5273\n",
      "Time taken for 1 epoch 197.43649315834045 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4161\n",
      "Epoch 7 Batch 100 Loss 0.3964\n",
      "Epoch 7 Batch 200 Loss 0.4223\n",
      "Epoch 7 Batch 300 Loss 0.3794\n",
      "Epoch 7 Batch 400 Loss 0.3602\n",
      "Epoch 7 Batch 500 Loss 0.4621\n",
      "Epoch 7 Batch 600 Loss 0.3813\n",
      "Epoch 7 Batch 700 Loss 0.3956\n",
      "Epoch 7 Batch 800 Loss 0.4387\n",
      "Epoch 7 Batch 900 Loss 0.4454\n",
      "Epoch 7 Batch 1000 Loss 0.3711\n",
      "Epoch 7 Loss 0.4097\n",
      "Time taken for 1 epoch 195.65587449073792 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2844\n",
      "Epoch 8 Batch 100 Loss 0.3336\n",
      "Epoch 8 Batch 200 Loss 0.3528\n",
      "Epoch 8 Batch 300 Loss 0.3128\n",
      "Epoch 8 Batch 400 Loss 0.3506\n",
      "Epoch 8 Batch 500 Loss 0.2182\n",
      "Epoch 8 Batch 600 Loss 0.3555\n",
      "Epoch 8 Batch 700 Loss 0.2661\n",
      "Epoch 8 Batch 800 Loss 0.3359\n",
      "Epoch 8 Batch 900 Loss 0.2769\n",
      "Epoch 8 Batch 1000 Loss 0.2945\n",
      "Epoch 8 Loss 0.3218\n",
      "Time taken for 1 epoch 198.95482921600342 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2211\n",
      "Epoch 9 Batch 100 Loss 0.2673\n",
      "Epoch 9 Batch 200 Loss 0.3318\n",
      "Epoch 9 Batch 300 Loss 0.2339\n",
      "Epoch 9 Batch 400 Loss 0.2570\n",
      "Epoch 9 Batch 500 Loss 0.1810\n",
      "Epoch 9 Batch 600 Loss 0.2897\n",
      "Epoch 9 Batch 700 Loss 0.2742\n",
      "Epoch 9 Batch 800 Loss 0.2919\n",
      "Epoch 9 Batch 900 Loss 0.2446\n",
      "Epoch 9 Batch 1000 Loss 0.2782\n",
      "Epoch 9 Loss 0.2569\n",
      "Time taken for 1 epoch 196.6909363269806 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1580\n",
      "Epoch 10 Batch 100 Loss 0.2023\n",
      "Epoch 10 Batch 200 Loss 0.2008\n",
      "Epoch 10 Batch 300 Loss 0.2470\n",
      "Epoch 10 Batch 400 Loss 0.2022\n",
      "Epoch 10 Batch 500 Loss 0.2312\n",
      "Epoch 10 Batch 600 Loss 0.2312\n",
      "Epoch 10 Batch 700 Loss 0.1939\n",
      "Epoch 10 Batch 800 Loss 0.1753\n",
      "Epoch 10 Batch 900 Loss 0.3567\n",
      "Epoch 10 Batch 1000 Loss 0.1905\n",
      "Epoch 10 Loss 0.2089\n",
      "Time taken for 1 epoch 201.0141532421112 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1475\n",
      "Epoch 11 Batch 100 Loss 0.1697\n",
      "Epoch 11 Batch 200 Loss 0.1658\n",
      "Epoch 11 Batch 300 Loss 0.1543\n",
      "Epoch 11 Batch 400 Loss 0.2337\n",
      "Epoch 11 Batch 500 Loss 0.1734\n",
      "Epoch 11 Batch 600 Loss 0.1698\n",
      "Epoch 11 Batch 700 Loss 0.1490\n",
      "Epoch 11 Batch 800 Loss 0.1719\n",
      "Epoch 11 Batch 900 Loss 0.1664\n",
      "Epoch 11 Batch 1000 Loss 0.1945\n",
      "Epoch 11 Loss 0.1739\n",
      "Time taken for 1 epoch 201.76115775108337 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1761\n",
      "Epoch 12 Batch 100 Loss 0.1827\n",
      "Epoch 12 Batch 200 Loss 0.1493\n",
      "Epoch 12 Batch 300 Loss 0.1392\n",
      "Epoch 12 Batch 400 Loss 0.1490\n",
      "Epoch 12 Batch 500 Loss 0.1206\n",
      "Epoch 12 Batch 600 Loss 0.1310\n",
      "Epoch 12 Batch 700 Loss 0.1475\n",
      "Epoch 12 Batch 800 Loss 0.1610\n",
      "Epoch 12 Batch 900 Loss 0.1531\n",
      "Epoch 12 Batch 1000 Loss 0.1009\n",
      "Epoch 12 Loss 0.1474\n",
      "Time taken for 1 epoch 199.32502126693726 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1177\n",
      "Epoch 13 Batch 100 Loss 0.1283\n",
      "Epoch 13 Batch 200 Loss 0.1255\n",
      "Epoch 13 Batch 300 Loss 0.1521\n",
      "Epoch 13 Batch 400 Loss 0.1069\n",
      "Epoch 13 Batch 500 Loss 0.1133\n",
      "Epoch 13 Batch 600 Loss 0.1082\n",
      "Epoch 13 Batch 700 Loss 0.1260\n",
      "Epoch 13 Batch 800 Loss 0.1129\n",
      "Epoch 13 Batch 900 Loss 0.1443\n",
      "Epoch 13 Batch 1000 Loss 0.1449\n",
      "Epoch 13 Loss 0.1265\n",
      "Time taken for 1 epoch 198.2801856994629 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1095\n",
      "Epoch 14 Batch 100 Loss 0.0787\n",
      "Epoch 14 Batch 200 Loss 0.0953\n",
      "Epoch 14 Batch 300 Loss 0.1098\n",
      "Epoch 14 Batch 400 Loss 0.1302\n",
      "Epoch 14 Batch 500 Loss 0.0994\n",
      "Epoch 14 Batch 600 Loss 0.0933\n",
      "Epoch 14 Batch 700 Loss 0.1209\n",
      "Epoch 14 Batch 800 Loss 0.1346\n",
      "Epoch 14 Batch 900 Loss 0.1295\n",
      "Epoch 14 Batch 1000 Loss 0.1376\n",
      "Epoch 14 Loss 0.1110\n",
      "Time taken for 1 epoch 200.65261125564575 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1112\n",
      "Epoch 15 Batch 100 Loss 0.0931\n",
      "Epoch 15 Batch 200 Loss 0.1335\n",
      "Epoch 15 Batch 300 Loss 0.0842\n",
      "Epoch 15 Batch 400 Loss 0.0903\n",
      "Epoch 15 Batch 500 Loss 0.1113\n",
      "Epoch 15 Batch 600 Loss 0.0694\n",
      "Epoch 15 Batch 700 Loss 0.1194\n",
      "Epoch 15 Batch 800 Loss 0.0918\n",
      "Epoch 15 Batch 900 Loss 0.0968\n",
      "Epoch 15 Batch 1000 Loss 0.1063\n",
      "Epoch 15 Loss 0.0985\n",
      "Time taken for 1 epoch 200.8940236568451 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0527\n",
      "Epoch 16 Batch 100 Loss 0.0642\n",
      "Epoch 16 Batch 200 Loss 0.0609\n",
      "Epoch 16 Batch 300 Loss 0.0961\n",
      "Epoch 16 Batch 400 Loss 0.0939\n",
      "Epoch 16 Batch 500 Loss 0.0802\n",
      "Epoch 16 Batch 600 Loss 0.0847\n",
      "Epoch 16 Batch 700 Loss 0.1044\n",
      "Epoch 16 Batch 800 Loss 0.0835\n",
      "Epoch 16 Batch 900 Loss 0.0976\n",
      "Epoch 16 Batch 1000 Loss 0.0694\n",
      "Epoch 16 Loss 0.0889\n",
      "Time taken for 1 epoch 198.37512230873108 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0753\n",
      "Epoch 17 Batch 100 Loss 0.0876\n",
      "Epoch 17 Batch 200 Loss 0.0692\n",
      "Epoch 17 Batch 300 Loss 0.0727\n",
      "Epoch 17 Batch 400 Loss 0.0840\n",
      "Epoch 17 Batch 500 Loss 0.0895\n",
      "Epoch 17 Batch 600 Loss 0.0905\n",
      "Epoch 17 Batch 700 Loss 0.1064\n",
      "Epoch 17 Batch 800 Loss 0.1493\n",
      "Epoch 17 Batch 900 Loss 0.0655\n",
      "Epoch 17 Batch 1000 Loss 0.0679\n",
      "Epoch 17 Loss 0.0809\n",
      "Time taken for 1 epoch 203.99619269371033 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0539\n",
      "Epoch 18 Batch 100 Loss 0.0615\n",
      "Epoch 18 Batch 200 Loss 0.0583\n",
      "Epoch 18 Batch 300 Loss 0.0540\n",
      "Epoch 18 Batch 400 Loss 0.0905\n",
      "Epoch 18 Batch 500 Loss 0.0503\n",
      "Epoch 18 Batch 600 Loss 0.0820\n",
      "Epoch 18 Batch 700 Loss 0.0719\n",
      "Epoch 18 Batch 800 Loss 0.0872\n",
      "Epoch 18 Batch 900 Loss 0.1060\n",
      "Epoch 18 Batch 1000 Loss 0.0646\n",
      "Epoch 18 Loss 0.0740\n",
      "Time taken for 1 epoch 200.6296513080597 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0780\n",
      "Epoch 19 Batch 100 Loss 0.0482\n",
      "Epoch 19 Batch 200 Loss 0.0633\n",
      "Epoch 19 Batch 300 Loss 0.0650\n",
      "Epoch 19 Batch 400 Loss 0.0631\n",
      "Epoch 19 Batch 500 Loss 0.0953\n",
      "Epoch 19 Batch 600 Loss 0.0758\n",
      "Epoch 19 Batch 700 Loss 0.0869\n",
      "Epoch 19 Batch 800 Loss 0.0453\n",
      "Epoch 19 Batch 900 Loss 0.0406\n",
      "Epoch 19 Batch 1000 Loss 0.0917\n",
      "Epoch 19 Loss 0.0695\n",
      "Time taken for 1 epoch 200.96777534484863 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0597\n",
      "Epoch 20 Batch 100 Loss 0.0509\n",
      "Epoch 20 Batch 200 Loss 0.0506\n",
      "Epoch 20 Batch 300 Loss 0.0985\n",
      "Epoch 20 Batch 400 Loss 0.0492\n",
      "Epoch 20 Batch 500 Loss 0.0623\n",
      "Epoch 20 Batch 600 Loss 0.0855\n",
      "Epoch 20 Batch 700 Loss 0.0661\n",
      "Epoch 20 Batch 800 Loss 0.0960\n",
      "Epoch 20 Batch 900 Loss 0.0780\n",
      "Epoch 20 Batch 1000 Loss 0.0757\n",
      "Epoch 20 Loss 0.0652\n",
      "Time taken for 1 epoch 203.01118659973145 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = model3.layers[0].initialize_states(64)\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint3.save(file_prefix = checkpoint_prefix3)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKsRJFDwREF3"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  \n",
    "\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence                                              \n",
    "  '''\n",
    "  attention_plot = np.zeros((output_length,input_length))\n",
    "  preprocessed_sentence = preprocess_sentence(input_sentence)\n",
    "  \n",
    "  print(preprocessed_sentence)\n",
    "\n",
    "  inputs = [inp_lang_tokenizer.word_index[i] for i in preprocessed_sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=input_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  enc_out, enc_hidden,enc_current = model3.layers[0](inputs, [tf.zeros((1, encoder_units)),tf.zeros((1, encoder_units))])\n",
    "\n",
    "  \n",
    "  dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] , 0)\n",
    "\n",
    "  for t in range(output_length):\n",
    "    predictions,state_h,state_c, attention_weights,context_vector =model3.layers[1].onestepdecoder(dec_input,\n",
    "                                                         enc_out,enc_hidden,enc_current)\n",
    "                                                        \n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    print(predicted_id)\n",
    "\n",
    "    result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      return result, preprocessed_sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, preprocessed_sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egKlLiYNXjMO"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  print('Input: %s' % (sent))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sent.split(' '))]\n",
    "  plot_attention(attention_plot, sent.split(' '), result.split(' '))\n",
    "\n",
    "  return sentence,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "l554f99cXJGb",
    "outputId": "d2bc38d5-ee17-49bb-9ba1-fd97e159f9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> ciao <end>\n",
      "1263\n",
      "hello \n",
      "2\n",
      "hello end \n",
      "Input: <start> ciao <end>\n",
      "Predicted translation: hello end \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent,pred = translate('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "U-KcWU5MUXYC",
    "outputId": "43364e3f-3bd3-4c55-9b24-8384b71a6133"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "score = 0\n",
    "for i in range(1000):\n",
    "  score = score + bleu.sentence_bleu(data['English'].iloc[i].split(' '), pred)\n",
    "\n",
    "\n",
    "final_bleu = score/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oxYfpvVKU9yV",
    "outputId": "71a35d9c-cba4-4bd8-9d3c-0a9428bc534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_bleu_score:   0.482982925661091\n"
     ]
    }
   ],
   "source": [
    "print(f'final_bleu_score:   {final_bleu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYpQCuMbVQPv"
   },
   "source": [
    "<h3> Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0ww6l2pVXhP"
   },
   "source": [
    "<h4> Concat score function shows the best result among all the score function i.e  general and dot "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2seq__Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
